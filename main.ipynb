{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Goals\n",
    "The goal of this project is to perform a sentiment analysis on search results from Google recommendations, such as \"Starbucks Oslo\" or \"Elkjøp Storo.\" The main idea is that relying solely on star ratings is an inconsistent way of measuring customer satisfaction for a given place. Therefore, I chose to implement sentiment analysis to get an idea of whether most reviews are, for example, \"frustrated,\" \"positive,\" or \"negative.\"\n",
    "\n",
    "For each search, the Google Places API will return up to five results—for instance, five Starbucks locations in Oslo. I will then perform a sentiment analysis on each place and conduct an overall NLP-based (Natural Language Processing) evaluation of all the places to decide on the best overall option.\n",
    "\n",
    "---\n",
    "\n",
    "# Approach\n",
    "\n",
    "## Logical Flow\n",
    "This project utilizes a sequential logical flow, resembling a pipeline or Chain of Thought (CoT).\n",
    "\n",
    "We first start by gathering the place IDs (a unique identifier for each business location) and peripheral data (name and address) using the Google Places API. This will give us up to five relevant places based on our search term (such as \"Starbucks Oslo\").\n",
    "\n",
    "Then, we obtain more data about each place using another Places API based on the place IDs. Here, we get access to the reviews, as well as ratings and additional peripheral data.\n",
    "\n",
    "At this point, we are ready to start our NLP sequence.\n",
    "\n",
    "- **Step One:** Loop through every place and every review for each place, writing a short sentiment summary of each review and labeling each review with single-word descriptors such as \"happy,\" \"frustrated,\" \"dirty,\" etc. This is the first step in our CoT. We also assign a 0-10 rating to each review, where 0 is highly negative and 10 is highly positive.\n",
    "- **Step Two:** Loop through every place and generate a short sentiment review, as well as sentiment labels for each place based on all the reviews for that place. This is the second step in our CoT and serves as a summarization of all the reviews for a single place. We then calculate the average rating for the place, which is done manually (i.e., outside the LLM).\n",
    "- **Step Three:** Decide on the best place by evaluating each summary, the labels for each place, and the average rating. The LLM decides on the best place holistically, rather than simply selecting the one with the highest rating. The result is presented as a print statement containing a short summary of why this is the best place, along with the rating and labels.\n",
    "\n",
    "---\n",
    "\n",
    "## Code Structure\n",
    "The code is structured in pairs of blocks. The first block contains the method definitions (e.g., `get_place_id(place_name)`), and the following block executes these methods with the necessary loops (e.g., `get_place_ids('Starbucks Oslo')`). The second block also prints the output.\n",
    "\n",
    "- First, we gather the place IDs using `get_place_ids`.\n",
    "- Then, we get the reviews using `get_reviews`.\n",
    "- Next, we label each review with sentiments using `sentiment_grade_review` (this method makes a lot of API calls and takes a couple of minutes).\n",
    "- After that, we perform sentiment grading for each place by summarizing the sentiments of each review using `make_overall_sentiment_rating`.\n",
    "- Finally, we decide on the best place by comparing the sentiments of each place using `select_best_place`.\n",
    "\n",
    "---\n",
    "\n",
    "# Challenges\n",
    "\n",
    "## API Costs and Speed\n",
    "This pipeline makes a lot of API calls, with one run typically taking two to three minutes. This is both slow and expensive. A possible solution might be to use threading for improved performance and to reduce the amount of text being processed. For instance, one could try to select the best place by just looking at the labels, disregarding the summaries. Experimenting with lighter, cheaper models might also be a reasonable approach.\n",
    "\n",
    "## Hallucinations\n",
    "During testing, I observed that the average score of some places was negative—for example, -3.7 on a 0-10 scale. This is a misjudgment by the model, as it sometimes interprets -10 as highly negative, 0 as neutral, and 10 as positive, even though the instructions specify that 0 is negative and 10 is positive.\n",
    "\n",
    "## Old Reviews\n",
    "Reviews that are old (e.g., 3+ years) are not as relevant. Ideally, I should have filtered these out.\n",
    "\n",
    "---\n",
    "\n",
    "# Key Takeaways\n",
    "\n",
    "## Vast Amounts of Unused NLP-Based Data\n",
    "There is a lot of unstructured (natural language) data waiting to be exploited. Such data is often user-generated—in the form of reviews, complaints, comments, etc.—and is extremely valuable for the business since it comes directly from the users.\n",
    "\n",
    "Other exciting applications may include advanced FAQ bots, sophisticated RAG-chains based on internal company data, and more. For an implementation of RAG, please try out my ChatGPT + Google Drive application, which creates an embedding store of your Google Drive on *drivesearcher.com*.\n",
    "\n",
    "## Modern LLMs Are Incredibly Good at Context\n",
    "The first LLMs, such as ChatGPT 3.0, were good at generating general text but struggled to understand user instructions (such as prompt tuning) and context. Modern LLMs, on the other hand, are highly adaptable and understand context in a meaningful way, making applications like the one showcased below much more useful.\n",
    "\n",
    "## Chain of Thought\n",
    "This script should have been built in LangChain or LangGraph, for that matter. As demonstrated by OpenAI, a chain of thought is a highly efficient way of enhancing a model's performance. Instead of using a single chat instance that tells the model, \"There are 10 reviews for each place. Here are 5 places; select the best one,\" it is better to break up the process into a chain of thought, similar to how humans would process the data mentally. This is the approach I have taken:\n",
    "- **First:** Mark the sentiment of each review.\n",
    "- **Second:** Mark the sentiment of each place based on the reviews.\n",
    "- **Third:** Decide on the best place based on sentiment.\n",
    "\n",
    "For a production environment, I would definitely have used LangChain, as it simplifies typing and data management, but due to the extra setup overhead, I decided to skip it for now.\n",
    "\n",
    "## Typing\n",
    "My biggest challenge along the way was not understanding the JSON structure of the previous method. For instance, I spent a lot of time going back and forth trying to determine where the name of the place was stored. If I had used typing from the start, the development process would have been much easier and quicker.\n",
    "\n",
    "\n",
    "---\n",
    "# Using LLMs versus traditional approaches\n",
    "As we can see in the bottom-most codeblock, based solely on star-rating one would want to go to Starbucks located in Nedre Storgate 6, 3015 Drammen, Norway. This is different from the models recomendation which (during this testrun) were  Starbucks at Jernbanetorget, siting its good customer service and convenient location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load env vars\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "PLACES_API_KEY = os.getenv(\"PLACES_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the necesary data from the GOOGLE PLACES API\n",
    "import requests\n",
    "\n",
    "#use semantic search to get the PLACE_ID, then fetch the reviews\n",
    "\n",
    "def get_place_ids(input_text='starbucks'):\n",
    "    #fields = \"name,rating,place_id\"\n",
    "\n",
    "    url = (\n",
    "        f\"https://maps.googleapis.com/maps/api/place/textsearch/json?\"\n",
    "        f\"query={input_text}&key={PLACES_API_KEY}\"\n",
    "    )\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    places = []\n",
    "    for place in data.get(\"results\", []):\n",
    "        places.append({\n",
    "            \"name\": place.get(\"name\"),\n",
    "            \"rating\": place.get(\"rating\"),\n",
    "            \"place_id\": place.get(\"place_id\"),\n",
    "            \"address\": place.get(\"formatted_address\")\n",
    "        })\n",
    "\n",
    "    # # Print results\n",
    "    # for p in places:\n",
    "    #     print(f\"Name: {p['name']}, Rating: {p['rating']}, Place ID: {p['place_id']}, Address: {p['address']}\")\n",
    "\n",
    "    return places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#retutns a list of {place_ids}\n",
    "\"\"\"\n",
    "[\n",
    "  {\n",
    "    \"name\": \"string\",\n",
    "    \"rating\": float,\n",
    "    \"place_id\": \"string\",\n",
    "    \"address\": \"string\"\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "\"\"\"\n",
    "places = get_place_ids()\n",
    "print(places)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode\n",
    "#fetch the reviews based on place id\n",
    "\n",
    "parameters = ['rating', 'reviews', 'types']\n",
    "fields_str = ','.join(parameters) \n",
    "\n",
    "base_url = \"https://maps.googleapis.com/maps/api/place/details/json\"\n",
    "\n",
    "def get_reviews(places :list):\n",
    "    places_with_reviews = {}\n",
    "\n",
    "    for place in places:\n",
    "        place_id = place['place_id']\n",
    "        name = place['name']\n",
    "        address = place['address']\n",
    "        rating = place['rating']\n",
    "\n",
    "        query_params = {\n",
    "            \"fields\": fields_str,\n",
    "            \"place_id\": place_id,\n",
    "            \"key\": PLACES_API_KEY\n",
    "        }\n",
    "        url = f\"{base_url}?{urlencode(query_params)}\"\n",
    "\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        #distill the necesary data\n",
    "        result = data['result']\n",
    "        reviews :list= result['reviews']\n",
    "\n",
    "        #extract the necesary data from the reviews\n",
    "        #that is: rating, text, time (maybe relative_time_description\n",
    "        #add an ID (index) for easier managment\n",
    "        formatted_reviews = []\n",
    "        for i in range(len(reviews)):\n",
    "            text = reviews[i]['text']\n",
    "            formatted_reviews.append({\n",
    "                \"id\": place_id,\n",
    "                \"index\": i,\n",
    "                \"rating\": rating,\n",
    "                \"text\": text ,\n",
    "                \"name\": name,\n",
    "                \"address\": address\n",
    "            })\n",
    "\n",
    "        places_with_reviews[place_id]=formatted_reviews\n",
    "    \n",
    "    return places_with_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "{\n",
    "  \"place_id_1\": [\n",
    "    {\n",
    "      \"id\": \"place_id_1\",\n",
    "      \"index\": int,\n",
    "      \"rating\": int,\n",
    "      \"text\": \"string\"\n",
    "      \"name\": str    },\n",
    "    ...\n",
    "  ],\n",
    "  \"place_id_2\": [\n",
    "    {\n",
    "      \"id\": \"place_id_2\",\n",
    "      \"index\": int,\n",
    "      \"rating\": int,\n",
    "      \"text\": \"string\"\n",
    "      \"name\" :str\n",
    "    },\n",
    "    ...\n",
    "  ],\n",
    "  ...\n",
    "}\n",
    "\"\"\"\n",
    "places_with_reviews = get_reviews(places=places)\n",
    "print(places_with_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoke the llm, prompt-tune it to become a sentiment analasysist\n",
    "#i use langgraph as i have used this before\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "    Asses the sentiment of the review below.\n",
    "    Make a short, couple sentence summary of the sentiment. \n",
    "    Add some single-word labels that describe teh sentiment.\n",
    "    Add a score of 0-10 where 10 is highly positive sentiment, while 0 is highly negative\"\n",
    "\"\"\"\n",
    "\n",
    "#summary: a short textual description of the sentiment\n",
    "#label: a one-word description of the sentiment such as \"happy\", \"sad\", \"disappointed\", \"delucional\"\n",
    "class Sentiment(BaseModel):\n",
    "    summary: str\n",
    "    labels: list[str]\n",
    "    score: int\n",
    "\n",
    "#returns a set of reviews\n",
    "def sentiment_grade_review(reviews :list):\n",
    "\n",
    "    #loop throiugh each review and store the data in llm_responses\n",
    "    llm_responses = []\n",
    "\n",
    "    for review in reviews:\n",
    "        place_id = review['id']\n",
    "        index = review['index']\n",
    "        rating = review['rating']\n",
    "        text = review['text']\n",
    "        name = review['name']\n",
    "        address = review['address']\n",
    "\n",
    "        print(f\"working on review {index+1}/{len(reviews)}\")\n",
    "\n",
    "        #skip the reviews with no text\n",
    "        if not text:\n",
    "            pass\n",
    "\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=OPENAI_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": text},\n",
    "            ],\n",
    "            response_format=Sentiment,\n",
    "        )\n",
    "        event = completion.choices[0].message.parsed\n",
    "\n",
    "        llm_responses.append({\n",
    "            \"id\": place_id,\n",
    "            \"index\": index,\n",
    "            \"name\": name,\n",
    "            \"address\": address,\n",
    "            \"rating\": rating,\n",
    "            \"text\": text,\n",
    "            \"summary\": event.summary,\n",
    "            \"labels\": event.labels,\n",
    "            \"score\": event.score\n",
    "        })\n",
    "    \n",
    "    return llm_responses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "{\n",
    "  \"place_id_1\": [\n",
    "    {\n",
    "      \"id\": \"place_id_1\",\n",
    "      \"index\": int,\n",
    "      \"rating\": int,\n",
    "      \"text\": \"string\",\n",
    "      \"summary\": \"string\",\n",
    "      \"name\": str\n",
    "      \"labels\": [\"string\", ...],\n",
    "      \"score\": int\n",
    "    },\n",
    "    ...\n",
    "  ],\n",
    "  \"place_id_2\": [\n",
    "    {\n",
    "      \"id\": \"place_id_2\",\n",
    "      \"index\": int,\n",
    "      \"rating\": int,\n",
    "      \"text\": \"string\",\n",
    "      \"summary\": \"string\",\n",
    "      \"name\": str\n",
    "      \"labels\": [\"string\", ...],\n",
    "      \"score\": int\n",
    "    },\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "places_with_sentiment = {}\n",
    "for index, place_id in enumerate(list(places_with_reviews.keys())):  \n",
    "    print(f\"\\n Working on place {index+1}/{len(places_with_reviews.keys())}\")\n",
    "    reviews = places_with_reviews[place_id] #list of reviews\n",
    "\n",
    "    sentiments =  sentiment_grade_review(reviews=reviews)\n",
    "    places_with_sentiment[place_id] = sentiments\n",
    "\n",
    "print(places_with_sentiment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "    Based on the labels and summaries below you are to make an overall sentimentanalysis.\n",
    "    Write a short summary describing the general sentiment.\n",
    "    Add the most common sentiment-labels\n",
    "\"\"\"\n",
    "\n",
    "class OverallSentiment(BaseModel):\n",
    "    summary: str\n",
    "    labels: list[str]\n",
    "\n",
    "\n",
    "def make_overall_sentiment_rating(sentiments :list):\n",
    "    number_of_reviews = len(sentiments)\n",
    "    total_score = 0\n",
    "    summaries = ''\n",
    "    total_labels = []\n",
    "\n",
    "    for s in sentiments:\n",
    "        # place_id = s['id']\n",
    "        # index = s['index']\n",
    "        # rating = s['rating']\n",
    "        # text = s['text']\n",
    "        summary = s['summary']\n",
    "        labels = s['labels']\n",
    "        score = s['score']\n",
    "\n",
    "        total_score += score\n",
    "        summaries += \"\\n\\n\\n\" + summary\n",
    "        total_labels.extend(labels)\n",
    "\n",
    "    avg_score = round(total_score / number_of_reviews, 1)\n",
    "\n",
    "    prompt = summaries + \"\\nLabels: \" + \", \".join(total_labels)\n",
    "\n",
    "    #pass to llm\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        response_format=OverallSentiment,\n",
    "    )\n",
    "    event = completion.choices[0].message.parsed\n",
    "\n",
    "    summary = event.summary\n",
    "    labels = event.labels\n",
    "\n",
    "    summarised_review = {\n",
    "        \"name\": sentiments[0]['name'], #extraxt the name and adr from the first review\n",
    "        \"address\": sentiments[0]['address'],\n",
    "        \"summary\": summary,\n",
    "        \"labels\": labels,\n",
    "        \"avg_score\": avg_score,\n",
    "    }\n",
    "\n",
    "    return summarised_review\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "{\n",
    "  \"place_id\": {\n",
    "    \"name\": str\n",
    "    \"summary\": \"Short textual summary of the overall sentiment.\",\n",
    "    \"labels\": [\n",
    "      \"label1\",\n",
    "      \"label2\",\n",
    "      \"label3\"\n",
    "    ],\n",
    "    \"avg_score\": float\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "summarised_reviews = {}\n",
    "for index, (place_id, sentiment) in enumerate(places_with_sentiment.items(), start=1):\n",
    "  print(f\"working on summarising reviews for place {index}/{len(places_with_sentiment.keys())}\")\n",
    "  pws = places_with_sentiment[place_id]\n",
    "  summarised_review = make_overall_sentiment_rating(sentiments=pws)\n",
    "  summarised_reviews[place_id] = summarised_review\n",
    "\n",
    "print(summarised_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "    Based on the sentiment summaries, labels and average score below you are to decide on the best place. Write a short summary about why this is the best place. \n",
    "    In the summary, include the average rating. Add labels describing the place.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Bestplace(BaseModel):\n",
    "    summary: str\n",
    "    labels: list[str]\n",
    "\n",
    "\"\"\"\n",
    "{\n",
    "  \"place_id\": {\n",
    "    \"summary\": \"Short textual summary of the overall sentiment.\",\n",
    "    \"name\":str\n",
    "    \"labels\": [\n",
    "      \"label1\",\n",
    "      \"label2\",\n",
    "      \"label3\"\n",
    "    ],\n",
    "    \"avg_score\": float\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def select_best_place(summarised_reviews :dict):\n",
    "    \n",
    "    prompt = ''\n",
    "    for place_id in summarised_reviews.keys():\n",
    "        place = summarised_reviews[place_id]\n",
    "        summary = place['summary']\n",
    "        labels = place['labels'] #list\n",
    "        name = place['name']\n",
    "        address = place['address']\n",
    "        avg_score = place['avg_score']\n",
    "\n",
    "        prompt += f\"\\n\\n\\n Name of the place: {name} \\n Address: {address} \\n Average 0-10 score, where 10 is highly positive is {avg_score} \\n Summary: {summary} \\n Labels: {labels}\"\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "    model=OPENAI_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "    response_format=OverallSentiment,\n",
    "    )\n",
    "\n",
    "    event = completion.choices[0].message.parsed\n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Garden Grains is the best place due to its high average sentiment score of 4.8. With customers praising it for its delicious and varied menu options, it stands out not only for the taste of its dishes but also for the quality of the ingredients used. Visitors appreciate the attention to detail and the creative twist on traditional dishes. The ambiance is welcoming, making it perfect for both casual dining and special occasions. The service consistently receives commendations, adding to the overall positive dining experience.\n",
      "\n",
      "\n",
      "\n",
      "This place has the following sentiment labels:\n",
      "\n",
      "Restaurant, Quality Ingredients, Creative Menu, Great Service, Cozy Ambiance\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "best_place = select_best_place(summarised_reviews=summarised_reviews)\n",
    "summary = best_place.summary\n",
    "labels = best_place.labels\n",
    "\n",
    "print(f\"\"\"\n",
    "{summary}\n",
    "\\n\\n\n",
    "This place has the following sentiment labels:\\n\n",
    "{\", \".join(labels)}\n",
    "      \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best place based solely on star-rating is Starbucks located in Nedre Storgate 6, 3015 Drammen, Norway.\n",
      "This place has a star-rating of 0\n",
      "\n",
      "\n",
      "\n",
      "Compared to our sentiment model: \n",
      "Garden Grains is the best place due to its high average sentiment score of 4.8. With customers praising it for its delicious and varied menu options, it stands out not only for the taste of its dishes but also for the quality of the ingredients used. Visitors appreciate the attention to detail and the creative twist on traditional dishes. The ambiance is welcoming, making it perfect for both casual dining and special occasions. The service consistently receives commendations, adding to the overall positive dining experience.\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "#Comapare my results to just the star-rating\n",
    "places = get_place_ids() #starbucks oslo\n",
    "best_place = None\n",
    "best_rating = 0\n",
    "\n",
    "for place in places:\n",
    "    rating = place['rating']\n",
    "    if rating>best_rating:\n",
    "        best_place=place\n",
    "        best_rating=rating\n",
    "\n",
    "print(f\"\"\"\n",
    "The best place based solely on star-rating is {place['name']} located in {place['address']}.\n",
    "This place has a star-rating of {best_rating}\n",
    "\\n\\n\n",
    "Compared to our sentiment model: \\n{summary}\n",
    "      \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
